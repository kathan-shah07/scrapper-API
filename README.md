#n8n workflow
![n8n-based Mutual Fund AI Assistant System](n8n-workflow.png)

--
A complete 3-layer system that scrapes mutual fund data from Groww, processes it through n8n RAG workflow, and provides an intelligent AI assistant that answers questions and performs actions via MCP tools.

---

## ğŸ“‹ Table of Contents

1. [System Overview](#system-overview)
2. [Layer 1: Local Scraper](#layer-1-local-scraper)
3. [Layer 2: n8n RAG Workflow](#layer-2-n8n-rag-workflow)
4. [Layer 3: Main Orchestrator](#layer-3-main-orchestrator)
5. [Complete Workflow Diagram](#complete-workflow-diagram)
6. [Setup & Usage](#setup--usage)

---

## ğŸ¯ System Overview

This project consists of three interconnected layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERACTION                          â”‚
â”‚              (Chat Interface / Questions)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LAYER 3: MAIN ORCHESTRATOR                      â”‚
â”‚  â€¢ AI Agent with RAG capabilities                           â”‚
â”‚  â€¢ Asks clarifying questions                                â”‚
â”‚  â€¢ Calls MCP tools (Gmail, Google Docs, Sheets)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LAYER 2: N8N RAG WORKFLOW                       â”‚
â”‚  â€¢ Uploads scraper JSON data                                â”‚
â”‚  â€¢ Creates vector embeddings                                â”‚
â”‚  â€¢ Stores in vector database                                â”‚
â”‚  â€¢ Retrieves relevant data for queries                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LAYER 1: LOCAL SCRAPER                         â”‚
â”‚  â€¢ Scrapes Groww mutual fund pages                          â”‚
â”‚  â€¢ Extracts structured data                                â”‚
â”‚  â€¢ Saves to JSON files                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Layer 1: Local Scraper

### What It Does

The local scraper extracts structured mutual fund data from Groww website and saves it as JSON files.

### How It Works

#### Step 1: Fetch the Webpage
```
User provides URL â†’ Scraper fetches HTML from Groww
```

**Methods Used:**
- **Playwright** (primary): Handles dynamic JavaScript content
- **Selenium** (fallback): Alternative browser automation
- **Requests** (fallback): Simple HTTP requests if browser automation fails

#### Step 2: Parse HTML Content
```
HTML â†’ BeautifulSoup â†’ Extract structured data
```

**Data Extracted:**
- Fund name, NAV, AUM
- Returns (1Y, 3Y, 5Y, since inception)
- Expense ratio, exit load, tax implications
- Top holdings (top 5, top 10)
- Advanced ratios (PE, PB, Alpha, Beta, Sharpe, Sortino)
- Category information and rankings
- Minimum investment amounts
- Risk level and fund type

#### Step 3: Save to JSON
```
Structured data â†’ JSON file â†’ data/mutual_funds/
```

**File Naming:**
- Extracted from URL slug
- Example: `nippon-india-flexi-cap-fund-direct-growth.json`

### Code Structure

```python
# Main scraper class
GrowwScraper
  â”œâ”€â”€ fetch_page()           # Gets HTML from URL
  â”œâ”€â”€ parse_fund_data()      # Extracts structured data
  â”œâ”€â”€ extract_parameters()   # Parses specific fields
  â””â”€â”€ save_json()            # Saves to JSON file

# Batch processing
batch_scrape.py
  â”œâ”€â”€ load_urls_from_file()  # Reads URLs from urls.txt
  â”œâ”€â”€ scrape_urls()          # Processes multiple URLs
  â””â”€â”€ main()                 # Entry point
```

### Example Usage

```bash
# Scrape single URL
python batch_scrape.py https://groww.in/mutual-funds/nippon-india-flexi-cap-fund-direct-growth

# Scrape from file
python batch_scrape.py --file urls.txt

# Output: data/mutual_funds/nippon-india-flexi-cap-fund-direct-growth.json
```

### Output Format

```json
[
  {
    "fund_name": "Nippon India Flexi Cap Fund Direct Growth",
    "nav": {
      "value": "â‚¹17.82",
      "as_of": "18 Dec 2025"
    },
    "fund_size": "â‚¹9,632.16Cr",
    "returns": {
      "1y": "0.8%",
      "3y": "16.9%",
      "since_inception": "14.2%"
    },
    "cost_and_tax": {
      "expense_ratio": "0.46%",
      "exit_load": "Exit load for units in excess of 10%...",
      "tax_implication": "..."
    },
    "top_5_holdings": [...],
    "source_url": "https://groww.in/mutual-funds/...",
    "last_scraped": "2025-12-19"
  }
]
```

---

## ğŸ”„ Layer 2: n8n RAG Workflow

### What It Does

The n8n workflow takes the scraper JSON files, processes them for RAG (Retrieval-Augmented Generation), and makes the data searchable for the AI agent.

### How It Works

#### Step 1: Upload Scraper Data
```
JSON file â†’ Form Trigger â†’ n8n Workflow
```

**Process:**
1. User uploads JSON file(s) via n8n form interface
2. Form Trigger receives the file(s)
3. Data is passed to the processing pipeline

#### Step 2: Load and Process Data
```
Form Trigger â†’ Default Data Loader â†’ Embeddings â†’ Vector Store
```

**Components:**
- **Default Data Loader**: Parses JSON and extracts text content
- **Embeddings Google Gemini**: Converts text to vector embeddings
- **Vector Store (Insert Mode)**: Stores embeddings in memory for retrieval

#### Step 3: Query Data (When User Asks Questions)
```
Chat Trigger â†’ AI Agent â†’ Query Data Tool â†’ Vector Store
```

**Flow:**
1. User sends chat message
2. Chat Trigger receives the message
3. AI Agent processes the query
4. Query Data Tool searches vector store for relevant information
5. Retrieved data is sent back to AI Agent
6. AI Agent generates response using retrieved context

### n8n Workflow Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA LOADING FLOW                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Form Trigger â”‚â”€â”€â”€â–º â”‚ Data Loader  â”‚â”€â”€â”€â–º â”‚ Vector Store â”‚
â”‚ (Upload)     â”‚     â”‚ (Parse JSON) â”‚     â”‚ (Insert)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Embeddings   â”‚
                     â”‚ (Gemini)     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUERY FLOW                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chat Trigger     â”‚ (User question)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Agent         â”‚â—„â”€â”€â”€â”€â”‚ Query Tool   â”‚â—„â”€â”€â”€â”€â”‚ Vector Store â”‚
â”‚ (Groq/Kimi)      â”‚     â”‚ (Search)     â”‚     â”‚ (Retrieve)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ If Node   â”‚ (Route based on output)
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â–º EMAIL_AGENT â”€â”€â–º MCP Client (Gmail)
         â”œâ”€â”€â”€â–º GOOGLE_DOC_AGENT â”€â”€â–º MCP Client (Docs)
         â””â”€â”€â”€â–º SHEETS_AGENT â”€â”€â–º MCP Client (Sheets)
```

### Key Components

**1. Form Trigger** (`formTrigger`)
- Receives uploaded JSON files
- Entry point for data ingestion

**2. Default Data Loader** (`documentDefaultDataLoader`)
- Parses JSON files
- Extracts text content for embedding

**3. Embeddings** (`embeddingsGoogleGemini`)
- Converts text to vector representations
- Used for both insertion and retrieval

**4. Vector Store** (`vectorStoreInMemory`)
- **Insert Mode**: Stores embeddings when data is uploaded
- **Retrieve Mode**: Searches for relevant data when queried

**5. Chat Trigger** (`chatTrigger`)
- Receives user questions
- Initiates query flow

**6. AI Agent** (`agent`)
- Main orchestrator for answering questions
- Uses Groq/Kimi model
- Decides when to use tools

**7. Query Data Tool** (`vectorStoreInMemory` in retrieve mode)
- Searches vector database
- Returns relevant mutual fund information

---

## ğŸ­ Layer 3: Main Orchestrator

### What It Does

The main orchestrator is an AI agent that:
1. Understands user queries about mutual funds
2. Asks clarifying questions when needed
3. Retrieves relevant data from the RAG system
4. Calls MCP tools (Gmail, Google Docs, Sheets) when requested

### How It Works

#### Step 1: Receive User Query
```
User Question â†’ Chat Trigger â†’ AI Agent
```

#### Step 2: Classify Query
The AI Agent evaluates the query and classifies it into one of four categories:

**1. OUT_OF_DOMAIN**
- Query is not about mutual funds
- Response: Brief description + 3 example questions

**2. IN_DOMAIN_INCOMPLETE**
- Query is about mutual funds but missing required context
- Response: 1-2 precise clarifying questions

**3. IN_DOMAIN_COMPLETE**
- Query is about mutual funds with sufficient context
- Action: Use Query Data Tool to retrieve information
- Response: Factual answer with citation link
- Follow-up: "Do you want this sent to your email?"

**4. TOOL_CALL**
- User wants to send email or update documents
- Action: Route to appropriate agent (EMAIL_AGENT, GOOGLE_DOC_AGENT, SHEETS_AGENT)

#### Step 3: Retrieve Data (If IN_DOMAIN_COMPLETE)
```
AI Agent â†’ Query Data Tool â†’ Vector Store â†’ Relevant Data â†’ AI Agent
```

**Process:**
1. AI Agent determines it needs data
2. Calls Query Data Tool with user query
3. Query Data Tool searches vector store
4. Returns relevant mutual fund information
5. AI Agent combines retrieved data with conversation context
6. Generates factual response

#### Step 4: Route to Tools (If TOOL_CALL)
```
AI Agent â†’ If Node â†’ Route to specific agent â†’ MCP Client â†’ External Tool
```

**Routing Logic:**
- **TOOL_EMAIL**: Routes to EMAIL_AGENT
- **TOOL_DOC**: Routes to GOOGLE_DOC_AGENT
- **TOOL_SHEETS**: Routes to SHEETS_AGENT

**MCP Tools Available:**
1. **Gmail Tool**: Send emails with agent response
![Sample Gmail note](MCP_Gmail.png)

2. **Google Docs Tool**: Update Google Docs with content
![Sample Google Doc note](MCP_Google_doc.png)

3. **Google Sheets Tool**: Log interactions in spreadsheet

### Decision Flow

```
                    User Query
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   AI Agent Evaluates â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
   OUT_OF_DOMAIN  INCOMPLETE      COMPLETE/TOOL
        â”‚                â”‚                â”‚
        â”‚                â”‚                â”‚
   Show examples    Ask questions    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                                    â”‚         â”‚
                                    â–¼         â–¼
                              COMPLETE    TOOL_CALL
                                    â”‚         â”‚
                                    â”‚         â”‚
                          Query Data Tool   Route to Agent
                                    â”‚         â”‚
                                    â”‚         â”‚
                          Generate Response  Call MCP Tool
```

### Example Interactions

#### Example 1: Complete Query
```
User: "What is the expense ratio of Nippon India Flexi Cap Fund?"

AI Agent:
1. Classifies as IN_DOMAIN_COMPLETE
2. Calls Query Data Tool
3. Retrieves: expense_ratio: "0.46%"
4. Responds: "The expense ratio of Nippon India Flexi Cap Fund Direct Growth is 0.46% (effective from 18 Dec 2025). [Citation link]"
5. Asks: "Do you want this sent to your email? If yes, please provide your email ID."
```

#### Example 2: Incomplete Query
```
User: "What is the exit load?"

AI Agent:
1. Classifies as IN_DOMAIN_INCOMPLETE
2. Responds: "1. Which mutual fund are you asking about?"
            "2. Are you asking about a specific fund or category?"
```

#### Example 3: Tool Call
```
User: "Send this to my email: user@example.com"

AI Agent:
1. Classifies as TOOL_CALL
2. Routes to EMAIL_AGENT
3. EMAIL_AGENT calls MCP Client (Gmail)
4. Email sent with previous agent response
```

#### Example 4: Out of Domain
```
User: "What's the weather today?"

AI Agent:
1. Classifies as OUT_OF_DOMAIN
2. Responds: "I'm a mutual fund facts-only assistant. I can help with:
            - ELSS lock-in period and exit load
            - Brokerage or DP charges
            - SIP mandates and fees
            - Fund categories, NAV, expense ratio, taxation
            
            Example questions:
            1. What is the expense ratio of Nippon India Flexi Cap Fund?
            2. What is the exit load for ELSS funds?
            3. What are the top holdings of SBI Large Cap Fund?"
```

### Safety Rules

The AI Agent follows strict safety rules:
- âœ… Provides factual information only
- âœ… No investment advice, opinions, or predictions
- âœ… Does NOT ask for or store PII (contact details, PAN, bank details, investment amounts)
- âœ… Reminds users not to share personal information
- âœ… Bases answers strictly on retrieved data

---

## ğŸ”„ Complete Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         COMPLETE SYSTEM FLOW                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LAYER 1: DATA COLLECTION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Groww Site  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Scrape
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scraper    â”‚â”€â”€â”€â–º â”‚ Parse HTML   â”‚â”€â”€â”€â–º â”‚ Save JSON    â”‚
â”‚ (Playwright) â”‚     â”‚ (BeautifulSoup)â”‚     â”‚ (data/mutual_funds/)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LAYER 2: DATA PROCESSING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  JSON Files  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Upload via Form
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Form Trigger â”‚â”€â”€â”€â–º â”‚ Data Loader  â”‚â”€â”€â”€â–º â”‚ Embeddings   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â”‚ Vector Store â”‚
                                         â”‚ (Insert)     â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LAYER 3: USER INTERACTION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Query   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chat Trigger â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI Agent    â”‚ (Evaluates query)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€ OUT_OF_DOMAIN â”€â”€â–º Show examples
       â”‚
       â”œâ”€â”€â”€ INCOMPLETE â”€â”€â–º Ask clarifying questions
       â”‚
       â”œâ”€â”€â”€ COMPLETE â”€â”€â–º Query Data Tool â”€â”€â–º Vector Store â”€â”€â–º Generate Response
       â”‚                                          â”‚
       â”‚                                          â–¼
       â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                   â”‚ Retrieve     â”‚
       â”‚                                   â”‚ Relevant Dataâ”‚
       â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â””â”€â”€â”€ TOOL_CALL â”€â”€â–º If Node â”€â”€â–º Route to Agent â”€â”€â–º MCP Client â”€â”€â–º Tool
                                                              â”‚
                                                              â”œâ”€â”€â–º Gmail
                                                              â”œâ”€â”€â–º Google Docs
                                                              â””â”€â”€â–º Google Sheets
```

---

## ğŸš€ Setup & Usage

### Prerequisites

1. **Python 3.8+**
2. **n8n instance** (cloud or self-hosted)
3. **Google API credentials** (for Gmail, Docs, Sheets)
4. **Groq API key** (for AI model)

### Installation

#### 1. Install Python Dependencies

```bash
pip install -r requirements.txt
playwright install chromium
```

#### 2. Setup n8n Workflows

1. Import `n8n/RAG-workflow.json` into n8n
2. Import `n8n/MCP server.json` into n8n
3. Configure credentials:
   - Google OAuth2 (Gmail, Docs, Sheets)
   - Groq API
   - Google Gemini API (for embeddings)

#### 3. Configure URLs

Edit `urls.txt` with mutual fund URLs:
```
https://groww.in/mutual-funds/nippon-india-flexi-cap-fund-direct-growth
https://groww.in/mutual-funds/nippon-india-large-cap-fund-direct-growth
```

### Usage Flow

#### Step 1: Scrape Data (Layer 1)

```bash
# Scrape mutual fund data
python batch_scrape.py --file urls.txt

# Output: JSON files in data/mutual_funds/
```

#### Step 2: Upload to n8n (Layer 2)

1. Open n8n RAG workflow
2. Click "Execute Workflow" or use form trigger
3. Upload JSON file(s) from `data/mutual_funds/`
4. Data is processed and stored in vector database

#### Step 3: Query via Chat (Layer 3)

1. Open n8n chat interface
2. Ask questions about mutual funds
3. AI agent retrieves data and responds
4. Optionally request email/document updates

### Example Workflow

```bash
# 1. Scrape data
python batch_scrape.py --file urls.txt

# 2. Upload to n8n (via web interface)
# - Go to n8n RAG workflow
# - Upload JSON files

# 3. Chat with AI
# User: "What is the expense ratio of Nippon India Flexi Cap Fund?"
# AI: "The expense ratio is 0.46%..."
# AI: "Do you want this sent to your email?"

# User: "Yes, send to user@example.com"
# AI: [Sends email via Gmail tool]
```

---

## ğŸ“ Project Structure

```
scrapper/
â”œâ”€â”€ groww_scraper.py          # Core scraper class
â”œâ”€â”€ batch_scrape.py            # Batch scraping script
â”œâ”€â”€ urls.txt                   # URLs to scrape
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ mutual_funds/         # Scraped JSON files
â”‚   â””â”€â”€ downloaded_html/      # Temporary HTML files
â””â”€â”€ n8n/
    â”œâ”€â”€ RAG-workflow.json     # RAG processing workflow
    â”œâ”€â”€ MCP server.json       # MCP tools workflow
    â””â”€â”€ ARCHITECTURE.txt      # n8n architecture details
```

---

## ğŸ”‘ Key Features

### Layer 1 (Scraper)
- âœ… Handles dynamic JavaScript content
- âœ… Extracts comprehensive fund data
- âœ… Batch processing support
- âœ… Structured JSON output

### Layer 2 (n8n RAG)
- âœ… Vector embeddings for semantic search
- âœ… In-memory vector store
- âœ… Automatic data processing
- âœ… Query-based retrieval

### Layer 3 (Orchestrator)
- âœ… Intelligent query classification
- âœ… Clarifying questions for incomplete queries
- âœ… Factual responses with citations
- âœ… MCP tool integration (Gmail, Docs, Sheets)
- âœ… Safety rules (no PII, no advice)

---

## ğŸ“ Notes

- The scraper uses Playwright/Selenium for dynamic content
- Vector store is in-memory (resets on n8n restart)
- AI agent uses Groq/Kimi model for fast responses
- All responses are factual only (no investment advice)
- MCP tools require proper OAuth2 setup

---

## ğŸ¤ Contributing

This is a personal project. For questions or issues, refer to the code comments in the respective files.

---

## ğŸ“„ License

This project is provided as-is for educational and personal use.
